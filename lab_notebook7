-------July 16---------
#PS7 notebook
#files copied from ensembl:
    Homo_sapiens.GRCh38.pep.all.fa.gz
    Danio_rerio.GRCz11.pep.all.fa.gz
    #files imported to talapas using wget to /projects/bgmp/mbabins5

#biomart files downloaded to C:
    #Gene stable ID, Gene Name, Protien Stable ID as parameters
    #Transferred over from download folder my cp //wsl/users/mbabins5, then scp to mbabins5@talapas-ln1.uoregon.edu:/projects/bgmp/mbabins5/bioinformatics/PS/PS7

#python script parsing over and retaining longest protein record per gene:
 file1 = 'Danio_rerio.GRCz11.pep.all.fa'

import re

gene_id = {} #keys=header, protein seqeunce, protein length, values=occurence

lines = [] #set empty list to fill with keys
gene = "" #setting gene to empty str
prot_len = "" #setting prot to empy str
head = "" #set header to empty str
prot_seq = "" #set protein sequence to empty str
n=0
with open(file1, 'r') as fh:
    for line in fh:
        if line.startswith('>'): #locate header line
            if gene not in gene_id and gene!="": #if not in dict and gene is not empty
                gene_id[gene] = [head, prot_seq, prot_len] #fill gene keys with this list
            elif gene != "" : #otherwise if it is empy
                if prot_len > gene_id[gene][2]: #if the prot is larger than that already in dict
                    gene_id[gene] = [head, prot_seq, prot_len] #add it's values to the dict
            prot_seq = "" #reset to empty str
            gene = re.search('gene:(ENS[A-Z]+[0-9]+)',line) #search for specific gene name
            gene = gene.group(1)
            head = line.strip()


#on talapas
#load module spider bbmap

#command for interactive session:
    srun --account=bgmp --partition=bgmp --nodes=1 --
    ntasks-per-node=1 --time=1:00:00 --cpus-per-task=1 --
    pty bash

#run stats on both files:
<filename> stats.sh
    saved to: 
        Human_LP_stats.txt , Zfish_LP_stats.txt

#pt2
#completed solely on talapas again - always have interacte node and never on login node

#building blastp database:
#!/bin/bash
#SBATCH --partition=bgmp                   ### Partition
#SBATCH --job-name=mbabins5blastdp         ### Job Name
#SBATCH --output=mbabins5blastdp.txt    ###File in which to store job output
#SBATCH --error=mbabins5blastdp.er    ### File to store error in
#SBATCH --nodes=1                       ### Needed to run job
#SBATCH --ntasks-per-node=1                   ### Run on a single CPU
#SBATCH --cpus-per-task=7             ### How many cpus needed for job
#SBATCH --time=0-99:00:00               ### Wall Clock Time limit hrs:min:sec
#SBATCH --account=bgmp                  ### Account used for job submission
#SBATCH --partition=bgmp                   ### Partition


makeblastdb -in parseDanio_rerio.GRCz11.pep.all.fa.fa -input_type fasta -out Zebra_Blast_DB  -dbtype prot
makeblastdb -in parseHomo_sapiens.GRCh38.pep.all.fa.fa -input_type fasta -out Human_Blast_DB  -dbtype prot


#alignment script for Human refence:
#!/bin/bash
#SBATCH --partition=bgmp                   ### Partition
#SBATCH --job-name=mbabins5BLAST         ### Job Name
#SBATCH --output=mbabins5BLAST.txt    ###File in which to store job output
#SBATCH --error=mbabins5BLAST.er    ### File to store error in
#SBATCH --nodes=1                       ### Needed to run job
#SBATCH --ntasks-per-node=1                   ### Run on a single CPU
#SBATCH --cpus-per-task=8             ### How many cpus needed for job
#SBATCH --time=0-99:00:00               ### Wall Clock Time limit hrs:min:sec
#SBATCH --account=bgmp                  ### Account used for job submission

conda activate bgmp_py37
module load BLAST+/2.2.31
$/usr/bin/time -v blastp -num_threads 8 -query parseHomo_sapiens.GRCh38.pep.all.fa.fa -evalue 1e6 -use_sw_tback -db Zebra_Blast_DB -outfmt 6 -out human_zfish_prot 

#alignment script with Zebra reference:
#!/bin/bash
#SBATCH --partition=bgmp                   ### Partition
#SBATCH --job-name=mbabins5BLASTZ         ### Job Name
#SBATCH --output=mbabins5BLASTZ.txt    ###File in which to store job output
#SBATCH --error=mbabins5BLASTZ.er    ### File to store error in
#SBATCH --nodes=1                       ### Needed to run job
#SBATCH --ntasks-per-node=1                   ### Run on a single CPU
#SBATCH --cpus-per-task=8             ### How many cpus needed for job
#SBATCH --time=0-99:00:00               ### Wall Clock Time limit hrs:min:sec
#SBATCH --account=bgmp                  ### Account used for job submission

conda activate bgmp_py37
module load BLAST+/2.2.31

$ /usr/bin/time -v blastp -num_threads 8 -query parseDanio_rerio.GRCz11.pep.all.fa.fa -evalue 1e6 -use_sw_tback -db Human_Blast_DB -outfmt 6 -out zfish_human_prot 

#problems still arised from having 8 cpus per task without specifying this in the in blastp line
#this lead to the script running on one node and taking a long time, so I had to rerun the script

#learned squeue -u command to check status of script

-----July 18------
#Insane storms, big power outage. Unable to check

----July 19------
#script is still running

JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
    12490912      bgmp mbabins5 mbabins5   R 2-05:54:09      1 n225
    12490911      bgmp mbabins5 mbabins5   R 2-05:54:21      1 n225

#worked with Pete to solve the problem but still there is a problem of my script taking to long to run
#will take the L on this assignment I think. :(
#lesson learned that sometimes it's okay to take the fallback and allow yourself piece of mind over 
#stress. In the end being relaxed internally will lead to greater performance and lead to greater experience
#life is too arbitrary and unpredictable to constantly worry. I will be okay. 